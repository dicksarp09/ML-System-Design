Great question! Here’s a summary of the key tools and technologies involved from the **data collection** phase all the way to the **deploy.sh** deployment script, based on the Scala code and scripts you shared:

---

### 1. **Data Collection & Storage**

* **ReactiveCouchbase** — Reactive API for interacting with Couchbase NoSQL database
* **Couchbase Client SDK** — For document storage and querying
* **Play JSON** — JSON serialization/deserialization

---

### 2. **Data Processing & Feature Generation**

* **Apache Spark** (RDDs, DataFrames, Spark SQL) — Distributed data processing framework
* **Spark MLlib & Spark ML** — Machine learning pipelines, feature engineering, classifiers, evaluators
* **NScala-Time** — Scala wrapper for Joda Time for date/time manipulation

---

### 3. **Model Training & Evaluation**

* **Spark ML algorithms** — Logistic Regression, Decision Tree, Random Forest, ChiSqSelector
* **Spark ML Pipeline** — For chaining feature transformations and modeling steps
* **Spark ML Evaluators** — BinaryClassificationEvaluator, etc.

---

### 4. **Model Serving / Prediction API**

* **Akka HTTP** — Lightweight HTTP server for REST API serving predictions
* **Spray JSON** — JSON marshalling/unmarshalling for REST APIs
* **Http4s** — Functional HTTP client and server (for microservices and model server)
* **Scalaz Task** — For async operations and concurrency

---

### 5. **Inter-service Communication**

* **Pyro (Python Remote Objects)** — For remote procedure calls to Python services (neural style transfer example)
* **Http4s Client** — HTTP calls between microservices
* **Akka Actors** — (Implicitly used in Akka HTTP) for concurrent request handling

---

### 6. **Build & Dependency Management**

* **SBT (Scala Build Tool)** — Building, compiling, testing, and packaging Scala code
* **sbt-assembly** — Plugin to create fat JARs including all dependencies

---

### 7. **Deployment**

* **Docker (Dockerfile, sbtdocker plugin)** — Containerization of the application for deployment
* **Shell scripting (deploy.sh)** — Automating git pull, compile, test, build, and rsync to artifact server
* **rsync** — For copying artifacts to remote servers

---

### Summary — How many tools?

| Category              | Tools                                      |
| --------------------- | ------------------------------------------ |
| Data storage          | Couchbase, Play JSON                       |
| Data processing       | Apache Spark, Spark MLlib, NScala-Time     |
| Model training        | Spark ML, Spark MLlib                      |
| Model serving         | Akka HTTP, Spray JSON, Http4s, Scalaz Task |
| RPC / Inter-service   | Pyro (Python), Http4s Client, Akka Actors  |
| Build & packaging     | SBT, sbt-assembly                          |
| Containerization      | Docker, sbtdocker                          |
| Deployment automation | Shell scripting, rsync                     |

**Total distinct major tools/technologies:** \~14

---

If you want, I can also break down which tools were used in each code snippet or help map this workflow into a diagram or a proper DevOps pipeline!
