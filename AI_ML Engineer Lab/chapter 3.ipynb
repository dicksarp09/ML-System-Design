{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478c6adc-509e-4cc3-97f5-4cb84fd131a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes binary classifier on Boolean features\n",
    "\n",
    "from typing import List, Set\n",
    "\n",
    "class BooleanFeature:\n",
    "    def __init__(self, name: str, value: bool):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.name == other.name and self.value == other.value\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.name, self.value))\n",
    "\n",
    "class BooleanLabel(BooleanFeature):\n",
    "    pass\n",
    "\n",
    "class BooleanInstance:\n",
    "    def __init__(self, features: Set[BooleanFeature], label: BooleanLabel):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "\n",
    "class NaiveBayesModel:\n",
    "    def __init__(self, instances: List[BooleanInstance]):\n",
    "        self.instances = instances\n",
    "        self.true_instances = [i for i in instances if i.label.value]\n",
    "        self.probability_true = len(self.true_instances) / len(instances)\n",
    "        \n",
    "        # all feature names\n",
    "        self.feature_names = set(f.name for i in instances for f in i.features)\n",
    "        \n",
    "        # Calculate P(feature=True | label=True) for each feature\n",
    "        self.feature_probabilities = {}\n",
    "        for fname in self.feature_names:\n",
    "            count_true = sum(\n",
    "                1 for inst in self.true_instances \n",
    "                for f in inst.features if f.name == fname and f.value\n",
    "            )\n",
    "            self.feature_probabilities[fname] = count_true / len(self.true_instances) if self.true_instances else 0.0\n",
    "\n",
    "        # Naive Bayes numerator = P(label=True) * product of P(features | label=True)\n",
    "        self.numerator = self.probability_true\n",
    "        for prob in self.feature_probabilities.values():\n",
    "            self.numerator *= prob\n",
    "\n",
    "    def probability_feature_vector(self, features: Set[BooleanFeature]) -> float:\n",
    "        matching_count = sum(1 for i in self.instances if i.features == features)\n",
    "        return matching_count / len(self.instances)\n",
    "\n",
    "    def predict(self, features: Set[BooleanFeature]) -> float:\n",
    "        # Return posterior proportional to numerator / P(features)\n",
    "        denominator = self.probability_feature_vector(features)\n",
    "        if denominator == 0:\n",
    "            return 0.0\n",
    "        return self.numerator / denominator\n",
    "\n",
    "# Example usage\n",
    "features1 = {BooleanFeature(\"high_absences\", True), BooleanFeature(\"passed\", True)}\n",
    "label1 = BooleanLabel(\"passed\", True)\n",
    "\n",
    "features2 = {BooleanFeature(\"high_absences\", False), BooleanFeature(\"passed\", False)}\n",
    "label2 = BooleanLabel(\"passed\", False)\n",
    "\n",
    "instances = [BooleanInstance(features1, label1), BooleanInstance(features2, label2)]\n",
    "\n",
    "model = NaiveBayesModel(instances)\n",
    "\n",
    "test_features = {BooleanFeature(\"high_absences\", True), BooleanFeature(\"passed\", True)}\n",
    "print(\"Prediction score:\", model.predict(test_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800fa6d0-d149-4713-bc55-53cd028986f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pyro4\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "class JobConfiguration:\n",
    "    def __init__(self, content_path, style_path, model_path, model_type,\n",
    "                 width=800, alpha=1.0, beta=200.0, iterations=5000):\n",
    "        self.content_path = content_path\n",
    "        self.style_path = style_path\n",
    "        self.model_path = model_path\n",
    "        self.model_type = model_type\n",
    "        self.width = width\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "\n",
    "def call_server(remote_server, job_config):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_call = executor.submit(\n",
    "            remote_server.generate,\n",
    "            job_config.content_path,\n",
    "            job_config.style_path,\n",
    "            job_config.model_path,\n",
    "            job_config.model_type,\n",
    "            job_config.width,\n",
    "            job_config.alpha,\n",
    "            job_config.beta,\n",
    "            job_config.iterations\n",
    "        )\n",
    "        try:\n",
    "            result = future_call.result(timeout=3600)  # 1 hour timeout\n",
    "            return result\n",
    "        except concurrent.futures.TimeoutError:\n",
    "            return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ns = Pyro4.locateNS()\n",
    "    remote_server = Pyro4.Proxy(ns.lookup(\"neuralserver\"))\n",
    "\n",
    "    job_config = JobConfiguration(\n",
    "        \"/path/to/content.jpg\",\n",
    "        \"/path/to/style.jpg\",\n",
    "        \"/path/to/model\",\n",
    "        \"VGG\",\n",
    "        iterations=1000\n",
    "    )\n",
    "\n",
    "    success = call_server(remote_server, job_config)\n",
    "    print(\"Style transfer success:\", success)\n",
    "\n",
    "    remote_server._pyroRelease()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3c2c9-1db6-453d-aca2-1c74419fe0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark_student_performance_pipeline.ipynb\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, IndexToString\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "spark = SparkSession.builder.appName(\"StudentPerformancePipeline\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# Load data (using local CSV or UCI direct download)\n",
    "data_path = \"student-mat.csv\"  # Download and put in working dir or update path\n",
    "df = spark.read.csv(data_path, header=True, sep=\";\")\n",
    "\n",
    "# Quick preprocessing: cast label to int (e.g., passed = G3 >= 10)\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "df = df.withColumn(\"G3_int\", col(\"G3\").cast(\"int\"))\n",
    "df = df.withColumn(\"passed\", when(col(\"G3_int\") >= 10, 1).otherwise(0))\n",
    "\n",
    "# Select features - for simplicity, pick numeric features only and assemble vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = [\"absences\", \"age\", \"failures\", \"G1\", \"G2\"]\n",
    "for c in feature_cols:\n",
    "    df = df.withColumn(c, col(c).cast(\"double\"))\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "data = assembler.transform(df).select(\"features\", \"passed\").withColumnRenamed(\"passed\", \"label\")\n",
    "\n",
    "# Index label and features\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "(trainingData, testData) = data.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Decision Tree classifier pipeline\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)\n",
    "\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt, labelConverter])\n",
    "\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5, truncate=False)\n",
    "\n",
    "# Random Forest classifier pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "model_rf = pipeline_rf.fit(trainingData)\n",
    "\n",
    "predictions_rf = model_rf.transform(testData)\n",
    "\n",
    "predictions_rf.select(\"predictedLabel\", \"label\", \"features\").show(5, truncate=False)\n",
    "\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
